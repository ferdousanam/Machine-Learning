{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferdous Anam\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Ferdous Anam\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.cross_validation import train_test_split # If you can use kFold the warning will be gone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('datasets/kddcup.data_10_percent.gz', header=None)\n",
    "\n",
    "# Categorize columns: \"protocol\", \"service\", \"flag\", \"attack_type\"\n",
    "raw_data[1], protocols= pd.factorize(raw_data[1])\n",
    "raw_data[2], services = pd.factorize(raw_data[2])\n",
    "raw_data[3], flags    = pd.factorize(raw_data[3])\n",
    "raw_data[41], attacks = pd.factorize(raw_data[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= raw_data.iloc[:,:raw_data.shape[1]-1]\n",
    "labels= raw_data.iloc[:,raw_data.shape[1]-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert them into numpy arrays\n",
    "#features= numpy.array(features)\n",
    "#labels= numpy.array(labels).ravel() # this becomes an 'horizontal' array\n",
    "labels= labels.values.ravel() # this becomes a 'horizontal' array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train: (395216, 41) (395216,)\n",
      "X_test, y_test: (98805, 41) (98805,)\n"
     ]
    }
   ],
   "source": [
    "# Separate data in train set and test set\n",
    "df= pd.DataFrame(features)\n",
    "# create training and testing vars\n",
    "# Note: train_size + test_size < 1.0 means we are subsampling\n",
    "# Use small numbers for slow classifiers, as KNN, Radius, SVC,...\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.8, test_size=0.2)\n",
    "print(\"X_train, y_train:\", X_train.shape, y_train.shape)\n",
    "print(\"X_test, y_test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    }
   ],
   "source": [
    "# Training, choose model by commenting/uncommenting clf=\n",
    "print(\"Training model\")\n",
    "clf= RandomForestClassifier(n_jobs=-1, random_state=3, n_estimators=102)#, max_features=0.8, min_samples_leaf=3, n_estimators=500, min_samples_split=3, random_state=10, verbose=1)\n",
    "#clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.externals import joblib\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the model from disk\n",
    "trained_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9999949394761346\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: \", trained_model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predicting\n",
    "print(\"Predicting\")\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing performance metrics\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing performance metrics\")\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "error = zero_one_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494021,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "labels.shape\n",
    "# target_names = dict(enumerate(labels))\n",
    "# np.unique(target_names)\n",
    "# print(target_names)\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = dict(zip(np.unique(labels), attacks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Printing Classification Report ==========================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           back.       1.00      1.00      1.00       446\n",
      "buffer_overflow.       1.00      0.67      0.80         9\n",
      "      ftp_write.       1.00      0.50      0.67         2\n",
      "   guess_passwd.       1.00      1.00      1.00        12\n",
      "           imap.       1.00      0.50      0.67         2\n",
      "        ipsweep.       1.00      0.99      1.00       265\n",
      "           land.       1.00      1.00      1.00         4\n",
      "     loadmodule.       0.00      0.00      0.00         1\n",
      "        neptune.       1.00      1.00      1.00     21431\n",
      "           nmap.       1.00      0.98      0.99        42\n",
      "         normal.       1.00      1.00      1.00     19402\n",
      "            pod.       1.00      1.00      1.00        45\n",
      "      portsweep.       1.00      1.00      1.00       210\n",
      "        rootkit.       0.00      0.00      0.00         4\n",
      "          satan.       1.00      0.99      1.00       329\n",
      "          smurf.       1.00      1.00      1.00     56218\n",
      "       teardrop.       1.00      1.00      1.00       180\n",
      "    warezclient.       0.99      1.00      1.00       198\n",
      "    warezmaster.       1.00      0.80      0.89         5\n",
      "\n",
      "     avg / total       1.00      1.00      1.00     98805\n",
      "\n",
      "============================= Confusion Matrix ===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ferdous Anam\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "reversefactor = target_names\n",
    "yy_test = np.vectorize(reversefactor.get)(y_test)\n",
    "yy_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "\n",
    "# print(\"============================= Labels Start ========================\")\n",
    "# print(np.unique(labels))\n",
    "# print(attacks)\n",
    "# a = [1,2]\n",
    "# b = np.array(a)\n",
    "# print(b.shape)\n",
    "\n",
    "# print(\"============================= Labels END ==========================\")\n",
    "\n",
    "print(\"============================= Printing Classification Report ==========================\")\n",
    "print(classification_report(yy_test, yy_pred))\n",
    "\n",
    "# # Making the Confusion Matrix\n",
    "print(\"============================= Confusion Matrix ===========================\")\n",
    "pd_cm = pd.crosstab(yy_test, yy_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_cm.to_csv('output/RF_Confusion_Matricx_Output_10_Percent.csv', index_label = 'attacks|attacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
